# Agent Loop è®¾è®¡

## ä» agent-loop åˆ° mini-claude-code

`agent-loop` é¡¹ç›®æ‰‹å†™äº†æ•´ä¸ªå¾ªç¯ï¼š

```typescript
// agent-loop çš„åšæ³•
for (let step = 0; step < 10; step++) {
  const text = await callLLMs(history)          // åŸç”Ÿ fetch
  const parsed = parseAssistant(text)            // æ‰‹å†™æ­£åˆ™è§£æ XML
  if (parsed.final) return parsed.final
  if (parsed.action) {
    const result = await executeTool(parsed.action)
    history.push({ role: 'user', content: `<observation>${result}</observation>` })
  }
}
```

`mini-claude-code` ç”¨ Vercel AI SDK æ›¿ä»£æ‰‹å†™éƒ¨åˆ†ï¼š

```typescript
// mini-claude-code çš„åšæ³•
const result = await generateText({
  model: provider('model-name'),
  system: await assembleSystemPrompt(),
  messages: history,
  tools: TOOLS,              // SDK è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨çŠ¶æ€æœº
  maxSteps: 20,             // SDK è‡ªåŠ¨å¾ªç¯ï¼Œç›´åˆ° LLM åœæ­¢è°ƒç”¨å·¥å…·
  onStepFinish: callback,   // æ¯æ­¥å›è°ƒï¼šæ‰“å° + context æ£€æŸ¥
})
```

SDK å¸®æˆ‘ä»¬åšæ‰äº†ï¼šå·¥å…·è°ƒç”¨çš„ JSON è§£æã€`tool_result` çš„å›å¡«ã€å¾ªç¯æ§åˆ¶ã€‚

## generateText å‚æ•°è¯¦è§£

```typescript
import { generateText } from 'ai'

const { text, steps } = await generateText({
  // æ¨¡å‹ï¼šä¸ƒç‰› Providerï¼ˆOpenAI å…¼å®¹ï¼‰
  model: qiniu('qwen-max-latest'),

  // ç³»ç»Ÿæç¤ºè¯ï¼šæ¯æ¬¡å¯¹è¯ç»„è£…ä¸€æ¬¡
  system: await assembleSystemPrompt(runtimeHints),

  // å†å²æ¶ˆæ¯ï¼šç»´æŠ¤åœ¨ AgentLoop å¤–éƒ¨ï¼Œæ”¯æŒå¤šè½®å¯¹è¯
  messages: history,

  // å·¥å…·æ³¨å†Œï¼šä» tools/index.ts å¯¼å…¥
  tools: TOOLS,

  // æœ€å¤§æ­¥æ•°ï¼šé˜²æ­¢æ— é™å¾ªç¯ï¼Œ20 æ­¥å¤Ÿç”¨ä¸è¿‡åˆ†
  maxSteps: 20,

  // æ¯æ­¥å®Œæˆçš„å›è°ƒ
  onStepFinish: async ({ text, toolCalls, toolResults, finishReason }) => {
    // 1. æ‰“å°å½“å‰æ­¥éª¤ï¼ˆæ•™å­¦ç”¨ï¼‰
    printStep(text, toolCalls, toolResults)

    // 2. æ£€æŸ¥ context å¤§å°ï¼ˆè§ context.mdï¼‰
    const shouldCompress = await contextManager.check(history)
    if (shouldCompress) {
      // ä¸­æ–­å½“å‰ generateTextï¼ˆé€šè¿‡æŠ›å‡ºç‰¹å®šé”™è¯¯ï¼‰
      throw new ContextOverflowError()
    }
  },
})
```

## ReAct å¾ªç¯å¯è§†åŒ–

SDK çš„ `maxSteps` èƒŒåï¼Œå°±æ˜¯æˆ‘ä»¬åœ¨ `agent-loop` é‡Œæ‰‹å†™çš„ ReAct å¾ªç¯ï¼š

```
ç¬¬ 1 æ­¥
  LLM è¾“å‡º: "æˆ‘éœ€è¦å…ˆè¯»å– package.json æ¥äº†è§£é¡¹ç›®ç»“æ„"
  Tool Call: read_file({ path: 'package.json' })
  Tool Result: '{"name": "my-app", "scripts": {...}}'

ç¬¬ 2 æ­¥
  LLM è¾“å‡º: "é¡¹ç›®ä½¿ç”¨ Viteï¼Œæˆ‘æ¥çœ‹ä¸€ä¸‹ vite.config.ts"
  Tool Call: read_file({ path: 'vite.config.ts' })
  Tool Result: [æ–‡ä»¶å†…å®¹]

ç¬¬ 3 æ­¥
  LLM è¾“å‡º: "æ‰¾åˆ°é—®é¢˜äº†ï¼Œéœ€è¦ä¿®æ”¹ç¬¬ 12 è¡Œçš„é…ç½®"
  Tool Call: edit_file({ path: 'vite.config.ts', old: '...', new: '...' })
  Tool Result: 'success'

ç¬¬ 4 æ­¥ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰
  LLM è¾“å‡º: "æˆ‘å·²ç»ä¿®æ”¹äº† vite.config.ts çš„ç¬¬ 12 è¡Œ..."
  finishReason: 'stop'  â†’ å¾ªç¯ç»“æŸ
```

## onStepFinish å›è°ƒçš„èŒè´£

è¿™ä¸ªå›è°ƒæ˜¯ä¸¤ä»¶äº‹çš„æ±‡åˆç‚¹ï¼š

### 1. æ•™å­¦è¾“å‡º

æ¯æ­¥æ‰“å°æ¸…æ¥šï¼Œè®©å­¦å‘˜çœ‹åˆ° Agent åœ¨å¹²ä»€ä¹ˆï¼š

```
[Step 1]
ğŸ¤” read_file({ path: "package.json" })
ğŸ“„ {"name": "my-app", ...}  (å·²æˆªæ–­ï¼ŒåŸå§‹é•¿åº¦ 2341 å­—ç¬¦)

[Step 2]
ğŸ¤” edit_file({ path: "src/index.ts", ... })
âœ… success
```

### 2. Context æ£€æŸ¥è§¦å‘ç‚¹

æ¯æ­¥å®Œæˆåï¼Œæ˜¯æ£€æŸ¥ token ç”¨é‡æœ€è‡ªç„¶çš„æ—¶æœºâ€”â€”æ­¤æ—¶ `history` å·²åŒ…å«æœ€æ–°çš„ `tool_result`ï¼Œtoken è®¡æ•°æœ€å‡†ç¡®ã€‚

## ä¸ƒç‰› Provider é…ç½®

ä¸ƒç‰›å¤§æ¨¡å‹æœåŠ¡å…¼å®¹ OpenAI åè®®ï¼Œå¯ä»¥ç›´æ¥ç”¨ `@ai-sdk/openai` çš„ `createOpenAI` åˆ›å»ºè‡ªå®šä¹‰ Providerï¼š

```typescript
// agent/provider.ts
import { createOpenAI } from '@ai-sdk/openai'

export const qiniu = createOpenAI({
  apiKey: process.env.QINIU_API_KEY,
  baseURL: 'https://api.qnaigc.com/v1',  // ä¸ƒç‰›æ¨ç†æœåŠ¡ç«¯ç‚¹
})

// ä½¿ç”¨æ—¶
const model = qiniu('qwen-max-latest')
```

æ¢æ¨¡å‹åªéœ€æ”¹ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ¢æˆ `claude-3-5-sonnet-20241022` æˆ– `gpt-4o` éƒ½è¡Œï¼ˆåªè¦ä¸ƒç‰›æ”¯æŒï¼‰ã€‚

## å¤šè½®å¯¹è¯çš„ history ç®¡ç†

`generateText` æ¯æ¬¡è°ƒç”¨åï¼Œéœ€è¦å°†æœ¬è½®çš„æ¶ˆæ¯è¿½åŠ åˆ° `history`ï¼Œä¾›ä¸‹ä¸€è½®å¯¹è¯ä½¿ç”¨ã€‚SDK æä¾›äº† `responseMessages` å­—æ®µï¼š

```typescript
// index.tsï¼ˆCLI å¤šè½®å¯¹è¯ï¼‰
const history: CoreMessage[] = []

async function chat(userInput: string) {
  const result = await agentLoop.run(userInput, history)

  // è¿½åŠ æœ¬è½®æ¶ˆæ¯ï¼ˆåŒ…å«æ‰€æœ‰ä¸­é—´æ­¥éª¤çš„ tool_call å’Œ tool_resultï¼‰
  history.push(...result.responseMessages)
}
```

è¿™æ · history é‡Œå°±åŒ…å«äº†å®Œæ•´çš„æ‰§è¡Œè½¨è¿¹ï¼Œä¸‹ä¸€è½® LLM èƒ½çœ‹åˆ°ä¹‹å‰åšäº†ä»€ä¹ˆã€‚

## é”™è¯¯å¤„ç†

| é”™è¯¯ç±»å‹ | å¤„ç†æ–¹å¼ |
|---------|---------|
| LLM API è°ƒç”¨å¤±è´¥ | æ•è·åå‘ŠçŸ¥ç”¨æˆ·ï¼Œä¸å´©æºƒ |
| å·¥å…·æ‰§è¡Œå¼‚å¸¸ | å°†é”™è¯¯ä¿¡æ¯ä½œä¸º tool_result è¿”å›ç»™ LLMï¼Œè®©å®ƒè‡ªä¿®æ­£ |
| maxSteps ç”¨å°½ | æç¤ºç”¨æˆ·ä»»åŠ¡æœªå®Œæˆï¼Œå¯ç»§ç»­è¿½é—® |
| ContextOverflow | æ‰§è¡Œå‹ç¼©ï¼Œé‡å»º historyï¼Œç»§ç»­å¯¹è¯ï¼ˆè§ context.mdï¼‰ |
| ç”¨æˆ·æ‹’ç»å±é™©å‘½ä»¤ | å°†"ç”¨æˆ·æ‹’ç»"ä½œä¸º tool_result è¿”å›ï¼ŒLLM ä¼šè°ƒæ•´ç­–ç•¥ |

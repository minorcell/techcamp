#!/usr/bin/env python3
"""
Comprehensive migration script for 2025 articles to Docusaurus blog
- Migrates all articles from 2025/ to website/blog/
- Translates Chinese titles/slugs to English kebab-case
- Generates proper frontmatter with tags
- Handles images
- Creates slug mapping report
"""
import os
import re
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

# Comprehensive Chinese to English slug mapping
SLUG_DICTIONARY = {
    # Technical terms
    'Â∑•Á®ãÂÆûË∑µ': 'engineering-practice',
    'ÂÜô‰ª£Á†Å': 'coding',
    'Á¨¨‰∏ÄÊ≠•': 'first-step',
    'ÂêåÂ≠¶': 'student',
    '‰∏∫‰ªÄ‰πà': 'why',
    'Âª∫ËÆÆ': 'suggest',
    'ÂÖ≥Ê≥®': 'follow',
    'ÂÆûËÆ≠Ëê•': 'techcamp',
    'Â∑•Á®ãÂ∏à': 'engineer',
    'Ê†∏ÂøÉÁ´û‰∫âÂäõ': 'core-competitiveness',
    '‰ºòÁßÄ': 'excellent',
    'ÁâπË¥®': 'qualities',
    '‰∏ÄË°å‰πãÂ∑Æ': 'one-line-difference',
    'Êñá‰ª∂Êú´Â∞æ': 'end-of-file',
    'Á©∫Ë°å': 'newline',
    'Á±ªÂûãÁ≥ªÁªü': 'type-system',
    'ÁºñËØëÂô®': 'compiler',
    'ÂÆûÁé∞': 'implementation',
    'ËæÖÂä©ÂºÄÂèë': 'assisted-development',
    'Êñ∞ËåÉÂºè': 'new-paradigm',
    'Êé¢Á¥¢': 'explore',
    'Êú™Êù•': 'future',
    'Êó∂‰ª£': 'era',
    'ÂèëÂ±ïËßÇ': 'development-perspective',
    'ÂèëÂ∏É': 'release',
    'ÂÖ®ÊôØÂõæ': 'roadmap',
    'ÂÖ®Ê∞ëÁºñÁ®ã': 'programming-for-all',
    'ËØ≠Ë®Ä': 'language',
    'ÂêàÂπ∂': 'merge',
    '‰∏âÈÄâ‰∏Ä': 'three-options',
    '‰∏ªÂàÜÊîØ': 'main-branch',
    'ÊÄé‰πàÈÄâ': 'which-to-choose',
    'ÊâçÁÆó': 'what-makes',
    'ÂÆåÊàê': 'complete',
    'Â∫îÁî®': 'application',
    'ÁêÜËß£': 'understanding',
    'ÊûÑÂª∫': 'building',
    'Â§öÊ®°ÊÄÅ': 'multimodal',
    'ÊêúÁ¥¢ÊúçÂä°': 'search-service',
    'ÂøÉÂæó': 'insights',
    '‰ª£Á†Å': 'code',
    'Ê†∏ÂøÉ': 'core',
    'È°πÁõÆ': 'project',
    '‰∫ßÂìÅÂºÄÂèë': 'product-development',
    'ÂÜ≥Á≠ñÂ±ÇÊ¨°': 'decision-layers',
    'Âø´ÈÄüÈõÜÊàê': 'rapid-integration',
    'ÁîüÊÄÅ': 'ecosystem',
    'Ê°•Ê¢Å': 'bridge',
    'ÁªòÂõæ': 'drawing',
    'ËûçÂÖ•': 'integration',
    '‰∫ßÂìÅ': 'product',
    'ÁºñËØë': 'compilation',
    'ËøêË°åÊó∂': 'runtime',
    'ÈõÜÊàê': 'integration',
    '‰æùËµñËØÜÂà´': 'dependency-identification',
    '‰∏ÄÈîÆ‰∫§‰ªò': 'one-click-delivery',
    'Êû∂ÊûÑËÆæËÆ°': 'architecture-design',
    '‰ªé‰ΩïÂÖ•Êâã': 'where-to-start',
    'ËÆ§Áü•‰Ωì‰ºö': 'insights',
    'Âá†ÁÇπ': 'several-points',
    'ÂÖ≥‰∫é': 'about',
    'ÊääÂ∞è‰∫ãÂÅöÂ•Ω': 'doing-small-things-well',
    '‰∏çÊòØ‰ªÄ‰πà': 'what-is-not',
    'ËÅä': 'on',
}

# Direct title to English slug mapping
TITLE_TO_SLUG = {
    'Â∑•Á®ãÂÆûË∑µÂàÜ‰∫´ | ÊääÂ∞è‰∫ãÂÅöÂ•Ω': 'engineering-practice-doing-small-things-well',
    'Â∑•Á®ãÂÆûË∑µÂàÜ‰∫´ÔΩú"ÂÜô‰ª£Á†Å"‰∏çÊòØÁ¨¨‰∏ÄÊ≠•ÔºÅ': 'engineering-practice-coding-is-not-first-step',
    'ÂêåÂ≠¶Ôºå‰∏∫‰ªÄ‰πàÊàëÂª∫ËÆÆ‰Ω†ÂÖ≥Ê≥® 1024 ÂÆûËÆ≠Ëê•Ôºü': 'why-you-should-join-1024-techcamp',
    'ÂΩì AI ËÉΩÂÜô‰ª£Á†ÅÔºåÂ∑•Á®ãÂ∏àÁöÑÊ†∏ÂøÉÁ´û‰∫âÂäõÊòØ‰ªÄ‰πàÔºü': 'engineer-core-competitiveness-in-ai-era',
    'ÊàëÁúº‰∏≠ÁöÑ‰ºòÁßÄÂ∑•Á®ãÂ∏àÁâπË¥®': 'qualities-of-excellent-engineers',
    '‰∏ÄË°å‰πãÂ∑ÆÔºö‰∏∫‰ªÄ‰πà‰Ω†ÁöÑÊñá‰ª∂Êú´Â∞æÂ∫îËØ•Áïô‰∏Ä‰∏™Á©∫Ë°åÔºü': 'why-end-files-with-newline',
    '‰ªéÁ±ªÂûãÁ≥ªÁªüÁúãXGoÁºñËØëÂô®ÁöÑÂÆûÁé∞': 'understanding-xgo-compiler-through-type-system',
    'AIËæÖÂä©ÂºÄÂèëÊñ∞ËåÉÂºèÔºö1024ÂÆûËÆ≠Ëê•Â∏¶‰Ω†Êé¢Á¥¢Êú™Êù•': 'ai-assisted-development-new-paradigm-with-techcamp',
    'ËÆ∏Âºè‰ºüËÅäAIÊó∂‰ª£‰∏ãÁöÑÂ∑•Á®ãÂ∏àÂèëÂ±ïËßÇ': 'xu-shiwei-on-engineer-development-in-ai-era',
    'ËÆ∏Âºè‰ºüÂèëÂ∏É XGo ÂÖ®ÊôØÂõæÔºöAI Êó∂‰ª£ÁöÑÂÖ®Ê∞ëÁºñÁ®ãËØ≠Ë®Ä': 'xu-shiwei-releases-xgo-roadmap-programming-for-all-in-ai-era',
    'GitHub PR ÂêàÂπ∂‰∏âÈÄâ‰∏ÄÔºö‰∏ªÂàÜÊîØËØ•ÊÄé‰πàÈÄâÔºü': 'github-pr-merge-strategies-which-to-choose',
    'Â¶Ç‰ΩïÊâçÁÆó"ÂÆåÊàê"‰∏Ä‰∏™AIÂ∫îÁî®': 'what-makes-ai-application-complete',
    '‰ªéÁ±ªÂûãÁ≥ªÁªüÁêÜËß£ LLGo ÁºñËØëÂô®ÁöÑÂÆûÁé∞': 'understanding-llgo-compiler-through-type-system',
    'Code Review ‰∏çÊòØ‰ªÄ‰πà‚Äî‚ÄîÁõòÁÇπ5‰∏™Â∏∏ËßÅËØØÂå∫': 'what-code-review-is-not',
    'Êû∂ÊûÑËÆæËÆ°‰ªé‰ΩïÂÖ•ÊâãÔºü': 'where-to-start-architecture-design',
    'ÂÖ≥‰∫éÊû∂ÊûÑËÆæËÆ°ÁöÑÂá†ÁÇπËÆ§Áü•‰Ωì‰ºö': 'insights-on-architecture-design',
    'SPX-AlgorithmÔºöÊûÑÂª∫Â§öÊ®°ÊÄÅÊêúÁ¥¢ÊúçÂä°ÁöÑ‰∏Ä‰∫õÂøÉÂæó': 'spx-algorithm-building-multimodal-search-service',
    '‰ª£Á†Å‰∏çÊòØÊ†∏ÂøÉÔºö‰ªé XLink È°πÁõÆÁúã‰∫ßÂìÅÂºÄÂèëÁöÑÂÜ≥Á≠ñÂ±ÇÊ¨°': 'code-is-not-core-decision-layers-in-xlink-project',
    'llpyg: LLGo Âø´ÈÄüÈõÜÊàê Python ÁîüÊÄÅÁöÑÊ°•Ê¢Å': 'llpyg-bridge-for-llgo-python-integration',
    'XÁªòÂõæ-Êàë‰ª¨ÊòØÂ¶Ç‰ΩïËÆ©AIÊõ¥Â•ΩÁöÑËûçÂÖ•Êàë‰ª¨ÁöÑ‰∫ßÂìÅÁöÑ': 'xdraw-how-to-integrate-ai-into-products',
    'XÁªòÂõæÔºöÊàë‰ª¨Â¶Ç‰ΩïËÆ© AI Êõ¥Â•ΩÂú∞ËûçÂÖ•‰∫ßÂìÅ': 'xdraw-how-to-integrate-ai-into-products',
    'LLGo ‰∏≠ Python ÁºñËØë‰∏éËøêË°åÊó∂ÈõÜÊàêÔºö‰ªé‰æùËµñËØÜÂà´Âà∞‰∏ÄÈîÆ‰∫§‰ªò': 'llgo-python-compilation-and-runtime-integration',
    'LLGo ‰∏≠ Python ÁºñËØë‰∏éËøêË°åÊó∂ÈõÜÊàê': 'llgo-python-compilation-and-runtime-integration',
}

# Tag mapping based on keywords
TAG_KEYWORDS = {
    'ai': ['AI', 'ai', 'Â§ßÊ®°Âûã', 'Êô∫ËÉΩ', '‰∫∫Â∑•Êô∫ËÉΩ', 'LLM'],
    'go': ['Go', 'go', 'golang', 'Go+', 'goplus'],
    'compiler': ['ÁºñËØëÂô®', 'XGo', 'LLGo', 'Á±ªÂûãÁ≥ªÁªü', 'typesystem', 'compiler'],
    'engineering': ['Â∑•Á®ãÂÆûË∑µ', 'Â∑•Á®ãÂ∏à', 'Code Review', 'GitHub', 'PR', 'Ë¥®Èáè', 'ËßÑËåÉ'],
    'architecture': ['Êû∂ÊûÑËÆæËÆ°', 'Êû∂ÊûÑ', 'ËÆæËÆ°', 'Á≥ªÁªü', 'architecture', 'design'],
    'xgo': ['XGo', 'xgo'],
    'llgo': ['LLGo', 'llgo', 'llpyg'],
    'career': ['ËÅå‰∏ö', 'ÂèëÂ±ï', 'ÊàêÈïø', 'ÁâπË¥®', 'Ê†∏ÂøÉÁ´û‰∫âÂäõ', 'career'],
    'python': ['Python', 'python', 'llpyg'],
    'tutorial': ['ÊïôÁ®ã', 'ÊåáÂçó', 'ÂÖ•Èó®', 'guide', 'tutorial'],
    'best-practices': ['ÊúÄ‰Ω≥ÂÆûË∑µ', 'ÂÆûË∑µ', 'ÂøÉÂæó', 'best-practices'],
}


def translate_to_english_slug(title: str) -> str:
    """Translate Chinese title to English kebab-case slug"""
    # Check direct mapping first
    if title in TITLE_TO_SLUG:
        return TITLE_TO_SLUG[title]

    # Build slug using dictionary
    slug_parts = []
    remaining_title = title

    # Try to match phrases from dictionary
    for cn, en in sorted(SLUG_DICTIONARY.items(), key=lambda x: -len(x[0])):
        if cn in remaining_title:
            remaining_title = remaining_title.replace(cn, f'|{en}|')

    # Split and clean
    parts = re.split(r'[|ÔΩú\sÔºö:Ôºü?ÔºÅ!Ôºå,„ÄÅ„ÄÇ]', remaining_title)
    for part in parts:
        if not part.strip():
            continue
        # If already English or alphanumeric, use as-is
        if re.match(r'^[a-zA-Z0-9-]+$', part):
            slug_parts.append(part.lower())

    # Join and clean up
    slug = '-'.join(slug_parts)
    slug = re.sub(r'[^a-z0-9-]', '', slug.lower())
    slug = re.sub(r'-+', '-', slug)
    slug = slug.strip('-')

    return slug[:100]  # Limit length


def extract_title_from_content(content: str) -> str:
    """Extract title from markdown content"""
    lines = content.strip().split('\n')
    for line in lines:
        if line.startswith('# '):
            return line[2:].strip()
    return None


def extract_tags(title: str, content: str, folder_name: str) -> List[str]:
    """Extract relevant tags based on keywords"""
    tags = set()
    text_to_check = (title + ' ' + content + ' ' + folder_name).lower()

    for tag, keywords in TAG_KEYWORDS.items():
        for keyword in keywords:
            if keyword.lower() in text_to_check:
                tags.add(tag)
                break

    # Always add engineering for general articles if no specific tag
    if not tags:
        tags.add('engineering')

    return sorted(list(tags))


def extract_description(content: str, max_length: int = 150) -> str:
    """Extract first meaningful paragraph as description"""
    # Remove title and empty lines
    lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]

    for line in lines:
        if len(line) > 20 and not line.startswith('```') and not line.startswith('*'):
            desc = line[:max_length]
            if len(line) > max_length:
                desc += '...'
            return desc

    return "1024 ÂÆûËÆ≠Ëê•ÊäÄÊúØÂàÜ‰∫´ÊñáÁ´†"


def migrate_article(source_path: Path, index: int, base_date: datetime) -> Dict:
    """Migrate a single article"""
    print(f"\nProcessing: {source_path}")

    with open(source_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Extract title
    title = extract_title_from_content(content)
    if not title:
        print(f"  ‚ö†Ô∏è  No title found, skipping")
        return None

    # Generate metadata
    folder_name = source_path.parent.name
    english_slug = translate_to_english_slug(title)
    tags = extract_tags(title, content, folder_name)
    description = extract_description(content)

    # Generate date (increment by 2 days for each article)
    article_date = base_date + timedelta(days=index * 2)
    date_str = article_date.strftime('%Y-%m-%d')

    # Remove the title from content
    content_lines = content.split('\n')
    if content_lines and content_lines[0].startswith('# '):
        content_lines = content_lines[1:]
        while content_lines and not content_lines[0].strip():
            content_lines.pop(0)

    content_body = '\n'.join(content_lines)

    # Handle images
    source_dir = source_path.parent
    for img_pattern in ['*.png', '*.jpg', '*.jpeg', '*.gif', '*.svg']:
        for img_file in source_dir.glob(img_pattern):
            dest_img_dir = Path('website/static/img/blog') / english_slug
            dest_img_dir.mkdir(parents=True, exist_ok=True)
            shutil.copy2(img_file, dest_img_dir / img_file.name)
            # Update image references
            content_body = content_body.replace(f'({img_file.name})', f'(/img/blog/{english_slug}/{img_file.name})')
            content_body = content_body.replace(f'[{img_file.name}]', f'[/img/blog/{english_slug}/{img_file.name}]')

    # Handle images in subdirectories
    for img_dir in source_dir.iterdir():
        if img_dir.is_dir():
            for img_pattern in ['*.png', '*.jpg', '*.jpeg', '*.gif', '*.svg']:
                for img_file in img_dir.glob(img_pattern):
                    dest_img_dir = Path('website/static/img/blog') / english_slug
                    dest_img_dir.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(img_file, dest_img_dir / img_file.name)
                    # Update references
                    content_body = content_body.replace(f'{img_dir.name}/{img_file.name}', f'/img/blog/{english_slug}/{img_file.name}')

    # Create frontmatter
    frontmatter = f"""---
slug: /blog/2025/{english_slug}
title: "{title}"
authors: [techcamp]
tags: [{', '.join(tags)}]
date: {date_str}
description: "{description}"
---

"""

    # Combine
    new_content = frontmatter + content_body

    # Generate filename
    new_filename = f"{date_str}-{english_slug}.md"
    new_path = Path('website/blog') / new_filename

    # Write file
    with open(new_path, 'w', encoding='utf-8') as f:
        f.write(new_content)

    print(f"  ‚úÖ Created: {new_filename}")
    print(f"  üìù Slug: {english_slug}")
    print(f"  üè∑Ô∏è  Tags: {', '.join(tags)}")

    return {
        'source': str(source_path),
        'destination': str(new_path),
        'original_title': title,
        'english_slug': english_slug,
        'date': date_str,
        'tags': tags
    }


def main():
    """Main migration function"""
    print("="*80)
    print("COMPREHENSIVE 2025 ARTICLES MIGRATION")
    print("="*80)

    # Get all markdown files from 2025/
    source_dir = Path('2025')
    source_files = sorted(source_dir.glob('*/*.md'))

    print(f"\nFound {len(source_files)} articles to migrate\n")

    # Base date for articles
    base_date = datetime(2025, 1, 15)

    results = []
    for index, source_file in enumerate(source_files):
        result = migrate_article(source_file, index, base_date)
        if result:
            results.append(result)

    # Print summary
    print("\n" + "="*80)
    print("MIGRATION SUMMARY")
    print("="*80)
    print(f"Total articles migrated: {len(results)}\n")

    # Group by tags
    tags_count = {}
    for result in results:
        for tag in result['tags']:
            tags_count[tag] = tags_count.get(tag, 0) + 1

    print("Tags distribution:")
    for tag, count in sorted(tags_count.items(), key=lambda x: x[1], reverse=True):
        print(f"  {tag}: {count} articles")

    print("\n" + "="*80)
    print("SLUG TRANSLATION MAPPING")
    print("="*80)
    for result in results:
        print(f"\n  Original: {result['original_title']}")
        print(f"  Slug:     {result['english_slug']}")
        print(f"  Date:     {result['date']}")

    # Save mapping to file
    mapping_file = Path('slug_mapping.json')
    import json
    with open(mapping_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ Slug mapping saved to {mapping_file}")
    print("\n" + "="*80)
    print("NEXT STEPS:")
    print("1. Review the migrated files in website/blog/")
    print("2. Test the build: cd website && npm install && npm run build")
    print("3. After verification, delete the 2025/ directory")
    print("="*80)


if __name__ == '__main__':
    main()
